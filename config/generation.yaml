llm:
  temperature: 0.2
  max_tokens: 512

prompts:
  strategy: qa
  enforce_grounding: true
