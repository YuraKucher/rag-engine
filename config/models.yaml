embeddings:
  backend: sentence_transformers
  model: all-MiniLM-L6-v2
  device: cpu
  normalize: true

llm:
  local:
    backend: ollama
    model: phi3:latest
    temperature: 0.0
    max_tokens: 512
    mode: dev

  colab:
    backend: hf
    model: google/flan-t5-large
    temperature: 0.2
    max_tokens: 256
    mode: production

