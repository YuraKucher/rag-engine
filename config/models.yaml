embeddings:
  default: sentence-transformers/all-MiniLM-L6-v2

llm:
  local:
    backend: ollama
    model: phi3:latest
    temperature: 0.0
    max_tokens: 512

  colab:
    backend: hf
    model: google/flan-t5-base
    temperature: 0.7
    max_tokens: 256
